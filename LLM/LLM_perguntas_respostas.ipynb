{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76ca7df",
   "metadata": {},
   "source": [
    "### Tópicos Especiais em Inteligência Artificial\n",
    "### Professor Ciniro Nametala - IFMG\n",
    "\n",
    "## Sistema de Perguntas e Respostas com Large Language Models (LLMs)\n",
    "\n",
    "Neste trabalho vamos utilizar um modelo de linguagem pré-treinado para criar um sistema de perguntas e respostas (*Question Answering - Q&A*). O modelo utilizado é o **BERT** (*Bidirectional Encoder Representations from Transformers*), uma arquitetura de rede neural baseada em *Transformers* que revolucionou o processamento de linguagem natural (NLP).\n",
    "\n",
    "O modelo específico utilizado é o `pierreguillou/bert-base-cased-squad-v1.1-portuguese`, que foi pré-treinado em português e fine-tunado no dataset SQuAD (Stanford Question Answering Dataset) adaptado para português. Este modelo é capaz de:\n",
    "\n",
    "1. Receber um **contexto** (texto de referência)\n",
    "2. Receber uma **pergunta** sobre o contexto\n",
    "3. Extrair a **resposta** diretamente do texto\n",
    "\n",
    "A arquitetura BERT utiliza o mecanismo de *self-attention* para capturar relações bidirecionais entre palavras, permitindo uma compreensão profunda do contexto textual.\n",
    "\n",
    "**Observação:** Este notebook requer que o modelo seja pré-baixado. Execute o script `LLM_download_modelo_bert_qa.py` antes de usar este notebook e garanta que o modelo será baixado para pasta `modelo_bert_qa_pt/` (a pasta será criada no momento da execução do script)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31713402",
   "metadata": {},
   "source": [
    "## 1. Preparação do ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "### 1.1 Configurações de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47771a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#funcao para deixar o jupyter com celulas preenchendo toda a tela\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalacao de pacotes necessarios (executar apenas uma vez)\n",
    "#!pip install transformers torch accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "### 1.2 Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9d810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#importacao de bibliotecas\n",
    "\n",
    "#bibliotecas basicas\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#bibliotecas para trabalhar com dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#biblioteca para tocar sons\n",
    "import pygame\n",
    "\n",
    "#bibliotecas para llm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a6",
   "metadata": {},
   "source": [
    "### 1.3 Verificando versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a1d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch: 2.9.1\n",
      "transformers: 4.57.5\n"
     ]
    }
   ],
   "source": [
    "#verificacao de versoes\n",
    "import transformers\n",
    "print('pytorch:', torch.__version__)\n",
    "print('transformers:', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5a6b7",
   "metadata": {},
   "source": [
    "### 1.4 Checagem de GPU/MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d279e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispositivo: mps\n",
      "nome: Apple Silicon (MPS)\n"
     ]
    }
   ],
   "source": [
    "#checagem de dispositivo disponivel\n",
    "def checarDispositivo():\n",
    "    #verifica se cuda esta disponivel (nvidia)\n",
    "    if torch.cuda.is_available():\n",
    "        dispositivo = 'cuda'\n",
    "        nome = torch.cuda.get_device_name(0)\n",
    "    #verifica se mps esta disponivel (apple silicon)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        dispositivo = 'mps'\n",
    "        nome = 'Apple Silicon (MPS)'\n",
    "    else:\n",
    "        dispositivo = 'cpu'\n",
    "        nome = 'CPU'\n",
    "    \n",
    "    print(f'dispositivo: {dispositivo}')\n",
    "    print(f'nome: {nome}')\n",
    "    return dispositivo\n",
    "\n",
    "dispositivo = checarDispositivo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c8",
   "metadata": {},
   "source": [
    "## 2. Carregamento do modelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b2c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo encontrado em: ./modelo_bert_qa_pt\n"
     ]
    }
   ],
   "source": [
    "#diretorio do modelo pre-baixado\n",
    "diretorio_modelo = './modelo_bert_qa_pt'\n",
    "\n",
    "#verificar se o modelo foi baixado\n",
    "if not os.path.exists(diretorio_modelo):\n",
    "    print('ERRO: modelo nao encontrado!')\n",
    "    print(f'execute primeiro o script: download_modelo_bert_qa.py')\n",
    "    print(f'diretorio esperado: {os.path.abspath(diretorio_modelo)}')\n",
    "else:\n",
    "    print(f'modelo encontrado em: {diretorio_modelo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67d36b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carregando tokenizer...\n",
      "tokenizer carregado\n",
      "carregando modelo...\n",
      "modelo carregado\n"
     ]
    }
   ],
   "source": [
    "#nome do modelo original (para referencia)\n",
    "nome_modelo = 'pierreguillou/bert-base-cased-squad-v1.1-portuguese'\n",
    "\n",
    "#carregar tokenizer do diretorio local\n",
    "print('carregando tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(diretorio_modelo)\n",
    "print('tokenizer carregado')\n",
    "\n",
    "#carregar modelo do diretorio local\n",
    "print('carregando modelo...')\n",
    "modelo = AutoModelForQuestionAnswering.from_pretrained(diretorio_modelo)\n",
    "print('modelo carregado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c78e90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo movido para: mps\n"
     ]
    }
   ],
   "source": [
    "#mover modelo para o dispositivo apropriado\n",
    "modelo = modelo.to(dispositivo)\n",
    "print(f'modelo movido para: {dispositivo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89f01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "#criar pipeline de question answering\n",
    "qa_pipeline = pipeline(\n",
    "    'question-answering',\n",
    "    model=modelo,\n",
    "    tokenizer=tokenizer,\n",
    "    device=dispositivo\n",
    ")\n",
    "print('pipeline criado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7c8d9",
   "metadata": {},
   "source": [
    "## 3. Configurações do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90a12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuracoes de exibicao\n",
    "exibir_tokens = True\n",
    "exibir_detalhes = True\n",
    "tocar_som = True\n",
    "\n",
    "#inicializar pygame para sons\n",
    "if tocar_som:\n",
    "    pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01b23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para tocar som de notificacao\n",
    "def tocarSom(frequencia=440, duracao=200):\n",
    "    if tocar_som:\n",
    "        try:\n",
    "            sample_rate = 44100\n",
    "            n_samples = int(sample_rate * duracao / 1000)\n",
    "            t = np.linspace(0, duracao / 1000, n_samples, False)\n",
    "            wave = np.sin(2 * np.pi * frequencia * t) * 0.3\n",
    "            wave = (wave * 32767).astype(np.int16)\n",
    "            stereo_wave = np.column_stack((wave, wave))\n",
    "            sound = pygame.sndarray.make_sound(stereo_wave)\n",
    "            sound.play()\n",
    "            pygame.time.wait(duracao)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8d9e0",
   "metadata": {},
   "source": [
    "## 4. Análise do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f1",
   "metadata": {},
   "source": [
    "### 4.1 Arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12b34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARQUITETURA DO MODELO BERT\n",
      "============================================================\n",
      "nome: pierreguillou/bert-base-cased-squad-v1.1-portuguese\n",
      "tipo: bert\n",
      "camadas (layers): 12\n",
      "dimensao oculta (hidden size): 768\n",
      "cabecas de atencao (attention heads): 12\n",
      "tamanho do vocabulario: 29794\n",
      "tamanho maximo de sequencia: 512\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#exibir arquitetura do modelo\n",
    "print('='*60)\n",
    "print('ARQUITETURA DO MODELO BERT')\n",
    "print('='*60)\n",
    "print(f'nome: {nome_modelo}')\n",
    "print(f'tipo: {modelo.config.model_type}')\n",
    "print(f'camadas (layers): {modelo.config.num_hidden_layers}')\n",
    "print(f'dimensao oculta (hidden size): {modelo.config.hidden_size}')\n",
    "print(f'cabecas de atencao (attention heads): {modelo.config.num_attention_heads}')\n",
    "print(f'tamanho do vocabulario: {modelo.config.vocab_size}')\n",
    "print(f'tamanho maximo de sequencia: {modelo.config.max_position_embeddings}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23c45d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de parametros: 108,334,082\n",
      "parametros treinaveis: 108,334,082\n",
      "tamanho aproximado: 413.3 MB\n"
     ]
    }
   ],
   "source": [
    "#contar parametros do modelo\n",
    "def contarParametros(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    treinaveis = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, treinaveis\n",
    "\n",
    "total_params, treinaveis_params = contarParametros(modelo)\n",
    "print(f'total de parametros: {total_params:,}')\n",
    "print(f'parametros treinaveis: {treinaveis_params:,}')\n",
    "print(f'tamanho aproximado: {total_params * 4 / 1024 / 1024:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0f1a2",
   "metadata": {},
   "source": [
    "### 4.2 Tokenizer e vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c34d56e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INFORMACOES DO TOKENIZER\n",
      "============================================================\n",
      "tipo: BertTokenizerFast\n",
      "tamanho do vocabulario: 29794\n",
      "tamanho maximo: 1000000000000000019884624838656\n",
      "tokens especiais: ['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#informacoes do tokenizer\n",
    "print('='*60)\n",
    "print('INFORMACOES DO TOKENIZER')\n",
    "print('='*60)\n",
    "print(f'tipo: {tokenizer.__class__.__name__}')\n",
    "print(f'tamanho do vocabulario: {tokenizer.vocab_size}')\n",
    "print(f'tamanho maximo: {tokenizer.model_max_length}')\n",
    "print(f'tokens especiais: {tokenizer.all_special_tokens}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45e67f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 tokens aleatórios do vocabulario:\n",
      "  10190: '##iterrâneo'\n",
      "  10191: 'Comércio'\n",
      "  10192: 'Mi'\n",
      "  10193: '##idado'\n",
      "  10194: 'reag'\n",
      "  10195: 'sons'\n",
      "  10196: 'Integra'\n",
      "  10197: 'hectares'\n",
      "  10198: 'substituiu'\n",
      "  10199: 'descendente'\n",
      "  10200: 'rem'\n",
      "  10201: 'lembra'\n",
      "  10202: 'ortodo'\n",
      "  10203: 'líquido'\n",
      "  10204: 'Christian'\n",
      "  10205: 'laboratório'\n",
      "  10206: 'Your'\n",
      "  10207: '##íferos'\n",
      "  10208: 'célula'\n",
      "  10209: 'cérebro'\n"
     ]
    }
   ],
   "source": [
    "#exibir alguns tokens do vocabulario\n",
    "if exibir_tokens:\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    vocab_ordenado = sorted(vocab.items(), key=lambda x: x[1])\n",
    "    \n",
    "    print('20 tokens aleatórios do vocabulario:')\n",
    "    for token, idx in vocab_ordenado[10190:10210]:\n",
    "        print(f'  {idx}: {repr(token)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1a2b3",
   "metadata": {},
   "source": [
    "### 4.3 Exemplo de tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56f78a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto original:\n",
      "  \"O Instituto Federal de Minas Gerais oferece cursos de tecnologia.\"\n",
      "\n",
      "tokens (11):\n",
      "  ['O', 'Instituto', 'Federal', 'de', 'Minas', 'Gerais', 'oferece', 'cursos', 'de', 'tecnologia', '.']\n",
      "\n",
      "token ids (13):\n",
      "  [101, 231, 2900, 2528, 125, 3474, 4192, 6158, 4736, 125, 4277, 119, 102]\n",
      "\n",
      "texto decodificado:\n",
      "  \"[CLS] O Instituto Federal de Minas Gerais oferece cursos de tecnologia. [SEP]\"\n"
     ]
    }
   ],
   "source": [
    "#demonstracao de tokenizacao\n",
    "texto_exemplo = 'O Instituto Federal de Minas Gerais oferece cursos de tecnologia.'\n",
    "\n",
    "print('texto original:')\n",
    "print(f'  \"{texto_exemplo}\"')\n",
    "print()\n",
    "\n",
    "#tokenizar\n",
    "tokens = tokenizer.tokenize(texto_exemplo)\n",
    "print(f'tokens ({len(tokens)}):')\n",
    "print(f'  {tokens}')\n",
    "print()\n",
    "\n",
    "#converter para ids\n",
    "token_ids = tokenizer.encode(texto_exemplo)\n",
    "print(f'token ids ({len(token_ids)}):')\n",
    "print(f'  {token_ids}')\n",
    "print()\n",
    "\n",
    "#decodificar de volta\n",
    "texto_decodificado = tokenizer.decode(token_ids)\n",
    "print('texto decodificado:')\n",
    "print(f'  \"{texto_decodificado}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4",
   "metadata": {},
   "source": [
    "## 5. Demonstração de Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "### 5.1 Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f67a89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao principal de perguntas e respostas\n",
    "def responderPergunta(contexto, pergunta, exibir=True):\n",
    "    #executar inferencia\n",
    "    resultado = qa_pipeline(question=pergunta, context=contexto)\n",
    "    \n",
    "    #extrair informacoes\n",
    "    resposta = resultado['answer']\n",
    "    score = resultado['score']\n",
    "    inicio = resultado['start']\n",
    "    fim = resultado['end']\n",
    "    \n",
    "    if exibir:\n",
    "        print('='*60)\n",
    "        print('PERGUNTA:')\n",
    "        print(f'  {pergunta}')\n",
    "        print()\n",
    "        print('RESPOSTA:')\n",
    "        print(f'  {resposta}')\n",
    "        print()\n",
    "        if exibir_detalhes:\n",
    "            print('DETALHES:')\n",
    "            print(f'  confianca: {score:.4f} ({score*100:.1f}%)')\n",
    "            print(f'  posicao no texto: caracteres {inicio} a {fim}')\n",
    "        print('='*60)\n",
    "    \n",
    "    tocarSom(880, 100)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78b90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para multiplas perguntas\n",
    "def responderMultiplasPerguntas(contexto, perguntas):\n",
    "    print('='*60)\n",
    "    print('CONTEXTO:')\n",
    "    print(f'  {contexto[:200]}...' if len(contexto) > 200 else f'  {contexto}')\n",
    "    print('='*60)\n",
    "    print()\n",
    "    \n",
    "    resultados = []\n",
    "    for pergunta in perguntas:\n",
    "        resultado = responderPergunta(contexto, pergunta, exibir=True)\n",
    "        resultados.append(resultado)\n",
    "        print()\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e6",
   "metadata": {},
   "source": [
    "### 5.2 Testes com textos de exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b89c01d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTEXTO:\n",
      "  \n",
      "O Instituto Federal de Educação, Ciência e Tecnologia de Minas Gerais (IFMG) é uma \n",
      "instituição de ensino público federal brasileira. Foi criado em 2008 através da Lei \n",
      "11.892. O IFMG possui 18 campi...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quando o IFMG foi criado?\n",
      "\n",
      "RESPOSTA:\n",
      "  2008\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9825 (98.2%)\n",
      "  posicao no texto: caracteres 149 a 153\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quantos campi o IFMG possui?\n",
      "\n",
      "RESPOSTA:\n",
      "  18\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9400 (94.0%)\n",
      "  posicao no texto: caracteres 192 a 194\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Onde está localizada a reitoria?\n",
      "\n",
      "RESPOSTA:\n",
      "  Belo Horizonte\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9670 (96.7%)\n",
      "  posicao no texto: caracteres 329 a 343\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quando foi fundada a Escola Agrícola de Bambuí?\n",
      "\n",
      "RESPOSTA:\n",
      "  1956\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9965 (99.6%)\n",
      "  posicao no texto: caracteres 550 a 554\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#texto de exemplo sobre o ifmg\n",
    "contexto_ifmg = \"\"\"\n",
    "O Instituto Federal de Educação, Ciência e Tecnologia de Minas Gerais (IFMG) é uma \n",
    "instituição de ensino público federal brasileira. Foi criado em 2008 através da Lei \n",
    "11.892. O IFMG possui 18 campi distribuídos pelo estado de Minas Gerais, oferecendo \n",
    "cursos técnicos, graduação e pós-graduação. A reitoria está localizada em Belo Horizonte. \n",
    "O instituto oferece cursos nas áreas de tecnologia, engenharia, administração, \n",
    "licenciaturas e outras. O campus Bambuí é um dos mais antigos, tendo origem na antiga \n",
    "Escola Agrícola de Bambuí fundada em 1956.\n",
    "\"\"\"\n",
    "\n",
    "perguntas_ifmg = [\n",
    "    'Quando o IFMG foi criado?',\n",
    "    'Quantos campi o IFMG possui?',\n",
    "    'Onde está localizada a reitoria?',\n",
    "    'Quando foi fundada a Escola Agrícola de Bambuí?'\n",
    "]\n",
    "\n",
    "resultados = responderMultiplasPerguntas(contexto_ifmg, perguntas_ifmg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5e6f7",
   "metadata": {},
   "source": [
    "## 6. Experimentos interativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7a8",
   "metadata": {},
   "source": [
    "### 6.1 Notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c90d12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTEXTO:\n",
      "  \n",
      "A seleção brasileira de futebol conquistou o pentacampeonato mundial em 2002, na Copa \n",
      "do Mundo realizada no Japão e na Coreia do Sul. O técnico Luiz Felipe Scolari comandou \n",
      "a equipe que tinha Ronal...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quem foi o técnico da seleção em 2002?\n",
      "\n",
      "RESPOSTA:\n",
      "  Luiz Felipe Scolari\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9920 (99.2%)\n",
      "  posicao no texto: caracteres 146 a 165\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quantos gols Ronaldo marcou?\n",
      "\n",
      "RESPOSTA:\n",
      "  8\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8709 (87.1%)\n",
      "  posicao no texto: caracteres 234 a 235\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Qual foi o placar da final?\n",
      "\n",
      "RESPOSTA:\n",
      "  2 a 0\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8865 (88.6%)\n",
      "  posicao no texto: caracteres 364 a 369\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Onde foi disputada a final?\n",
      "\n",
      "RESPOSTA:\n",
      "  Yokohama\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.2073 (20.7%)\n",
      "  posicao no texto: caracteres 326 a 334\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Contra quem o Brasil jogou a final?\n",
      "\n",
      "RESPOSTA:\n",
      "  Alemanha\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8444 (84.4%)\n",
      "  posicao no texto: caracteres 294 a 302\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#texto de noticia\n",
    "contexto_noticia = \"\"\"\n",
    "A seleção brasileira de futebol conquistou o pentacampeonato mundial em 2002, na Copa \n",
    "do Mundo realizada no Japão e na Coreia do Sul. O técnico Luiz Felipe Scolari comandou \n",
    "a equipe que tinha Ronaldo como principal artilheiro, com 8 gols marcados no torneio. \n",
    "A final foi disputada contra a Alemanha no dia 30 de junho, em Yokohama, com vitória \n",
    "brasileira por 2 a 0. Os gols foram marcados por Ronaldo, que se recuperava de uma \n",
    "grave lesão no joelho. Outros jogadores importantes daquela campanha foram Rivaldo, \n",
    "Ronaldinho Gaúcho, Cafu e Roberto Carlos.\n",
    "\"\"\"\n",
    "\n",
    "perguntas_noticia = [\n",
    "    'Quem foi o técnico da seleção em 2002?',\n",
    "    'Quantos gols Ronaldo marcou?',\n",
    "    'Qual foi o placar da final?',\n",
    "    'Onde foi disputada a final?',\n",
    "    'Contra quem o Brasil jogou a final?'\n",
    "]\n",
    "\n",
    "resultados = responderMultiplasPerguntas(contexto_noticia, perguntas_noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a8b9",
   "metadata": {},
   "source": [
    "### 6.2 Textos científicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01e23f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTEXTO:\n",
      "  \n",
      "A Inteligência Artificial (IA) é um campo da ciência da computação que busca criar \n",
      "sistemas capazes de realizar tarefas que normalmente requerem inteligência humana. \n",
      "O termo foi cunhado por John Mc...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quem cunhou o termo Inteligência Artificial?\n",
      "\n",
      "RESPOSTA:\n",
      "  John McCarthy\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9990 (99.9%)\n",
      "  posicao no texto: caracteres 193 a 206\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Em que ano foi a conferência de Dartmouth?\n",
      "\n",
      "RESPOSTA:\n",
      "  1956\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9964 (99.6%)\n",
      "  posicao no texto: caracteres 210 a 214\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  O que é deep learning?\n",
      "\n",
      "RESPOSTA:\n",
      "  aprendizado profundo\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8782 (87.8%)\n",
      "  posicao no texto: caracteres 385 a 405\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quantos parâmetros tem o GPT-3?\n",
      "\n",
      "RESPOSTA:\n",
      "  175 bilhões\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8989 (89.9%)\n",
      "  posicao no texto: caracteres 577 a 588\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quem lançou o GPT-3?\n",
      "\n",
      "RESPOSTA:\n",
      "  OpenAI\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9800 (98.0%)\n",
      "  posicao no texto: caracteres 554 a 560\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#texto cientifico sobre inteligencia artificial\n",
    "contexto_ia = \"\"\"\n",
    "A Inteligência Artificial (IA) é um campo da ciência da computação que busca criar \n",
    "sistemas capazes de realizar tarefas que normalmente requerem inteligência humana. \n",
    "O termo foi cunhado por John McCarthy em 1956, durante a conferência de Dartmouth. \n",
    "As principais subáreas da IA incluem aprendizado de máquina, processamento de linguagem \n",
    "natural, visão computacional e robótica. O aprendizado profundo (deep learning) é uma \n",
    "técnica de aprendizado de máquina que utiliza redes neurais artificiais com múltiplas \n",
    "camadas. O modelo GPT-3, lançado pela OpenAI em 2020, possui 175 bilhões de parâmetros \n",
    "e representa um marco no desenvolvimento de modelos de linguagem.\n",
    "\"\"\"\n",
    "\n",
    "perguntas_ia = [\n",
    "    'Quem cunhou o termo Inteligência Artificial?',\n",
    "    'Em que ano foi a conferência de Dartmouth?',\n",
    "    'O que é deep learning?',\n",
    "    'Quantos parâmetros tem o GPT-3?',\n",
    "    'Quem lançou o GPT-3?'\n",
    "]\n",
    "\n",
    "resultados = responderMultiplasPerguntas(contexto_ia, perguntas_ia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b9c0",
   "metadata": {},
   "source": [
    "### 6.3 Texto livre (interativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e12f34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#celula interativa - insira seu proprio contexto e pergunta\n",
    "\n",
    "meu_contexto = \"\"\"\n",
    "Cole aqui o texto que deseja usar como contexto para as perguntas.\n",
    "Pode ser uma notícia, um artigo, um trecho de livro ou qualquer texto.\n",
    "\"\"\"\n",
    "\n",
    "minha_pergunta = \"Sua pergunta aqui?\"\n",
    "\n",
    "#descomente a linha abaixo para executar\n",
    "#resultado = responderPergunta(meu_contexto, minha_pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9c0d1",
   "metadata": {},
   "source": [
    "## 7. Análise de confiança e limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e2",
   "metadata": {},
   "source": [
    "### 7.1 Testando limites do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f23a45b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTE DE LIMITES DO MODELO\n",
      "============================================================\n",
      "observe como o modelo se comporta com perguntas cuja resposta\n",
      "nao esta presente no contexto fornecido\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Qual é a capital do Brasil?\n",
      "\n",
      "RESPOSTA:\n",
      "  Brasília\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.9853 (98.5%)\n",
      "  posicao no texto: caracteres 129 a 137\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Qual é a população do Brasil?\n",
      "\n",
      "RESPOSTA:\n",
      "  215 milhões\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8053 (80.5%)\n",
      "  posicao no texto: caracteres 82 a 93\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Quem é o presidente do Brasil?\n",
      "\n",
      "RESPOSTA:\n",
      "  Brasília\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.2278 (22.8%)\n",
      "  posicao no texto: caracteres 129 a 137\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PERGUNTA:\n",
      "  Qual é a moeda do Brasil?\n",
      "\n",
      "RESPOSTA:\n",
      "  português\n",
      "\n",
      "DETALHES:\n",
      "  confianca: 0.8486 (84.9%)\n",
      "  posicao no texto: caracteres 178 a 187\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testando perguntas cujas respostas nao estao no texto\n",
    "contexto_teste = \"\"\"\n",
    "O Brasil é o maior país da América do Sul, com uma população de aproximadamente \n",
    "215 milhões de habitantes. A capital do país é Brasília, fundada em 1960. \n",
    "O idioma oficial é o português.\n",
    "\"\"\"\n",
    "\n",
    "perguntas_teste = [\n",
    "    'Qual é a capital do Brasil?',           #resposta no texto\n",
    "    'Qual é a população do Brasil?',         #resposta no texto\n",
    "    'Quem é o presidente do Brasil?',        #resposta nao esta no texto\n",
    "    'Qual é a moeda do Brasil?'              #resposta nao esta no texto\n",
    "]\n",
    "\n",
    "print('TESTE DE LIMITES DO MODELO')\n",
    "print('='*60)\n",
    "print('observe como o modelo se comporta com perguntas cuja resposta')\n",
    "print('nao esta presente no contexto fornecido')\n",
    "print('='*60)\n",
    "print()\n",
    "\n",
    "for pergunta in perguntas_teste:\n",
    "    resultado = responderPergunta(contexto_teste, pergunta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1e2f3",
   "metadata": {},
   "source": [
    "### 7.2 Comparativo de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a34b56c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARATIVO DE CONFIANCA\n",
      "======================================================================\n",
      "pergunta                                 resposta        confianca  no texto?\n",
      "======================================================================\n",
      "Onde Einstein nasceu?                    Ulm, na Alem... 0.8927     sim\n",
      "Quando Einstein ganhou o Nobel?          1921            0.9860     sim\n",
      "Para onde Einstein emigrou?              Estados Unid... 0.9417     sim\n",
      "Qual era a cor favorita de Einstein?     relatividade    0.0742     nao\n",
      "Quantos filhos Einstein teve?            1933            0.1286     nao\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#gerar tabela comparativa de confianca\n",
    "contexto_comp = \"\"\"\n",
    "Albert Einstein nasceu em 14 de março de 1879 em Ulm, na Alemanha. Ele desenvolveu \n",
    "a teoria da relatividade e ganhou o Prêmio Nobel de Física em 1921. Einstein emigrou \n",
    "para os Estados Unidos em 1933 e trabalhou no Instituto de Estudos Avançados em Princeton. \n",
    "Ele faleceu em 18 de abril de 1955.\n",
    "\"\"\"\n",
    "\n",
    "perguntas_comp = [\n",
    "    ('Onde Einstein nasceu?', True),\n",
    "    ('Quando Einstein ganhou o Nobel?', True),\n",
    "    ('Para onde Einstein emigrou?', True),\n",
    "    ('Qual era a cor favorita de Einstein?', False),\n",
    "    ('Quantos filhos Einstein teve?', False)\n",
    "]\n",
    "\n",
    "print('COMPARATIVO DE CONFIANCA')\n",
    "print('='*70)\n",
    "print(f'{\"pergunta\":<40} {\"resposta\":<15} {\"confianca\":<10} {\"no texto?\"}')\n",
    "print('='*70)\n",
    "\n",
    "for pergunta, esperado in perguntas_comp:\n",
    "    resultado = qa_pipeline(question=pergunta, context=contexto_comp)\n",
    "    resposta = resultado['answer'][:12] + '...' if len(resultado['answer']) > 12 else resultado['answer']\n",
    "    score = resultado['score']\n",
    "    print(f'{pergunta:<40} {resposta:<15} {score:.4f}     {\"sim\" if esperado else \"nao\"}')\n",
    "\n",
    "print('='*70)\n",
    "tocarSom(660, 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
